{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Assalamualaikum^-^ \u00b6 Selamat Datang Di Halaman Tugas Penambangan Data \u00b6 Nama : Nur Khofifah Nim : 180411100139 Jurusan : Teknik Informatika Angkatan : 2018 Semester : 3 Mata Kuliah : Penambangan data-5D Perguruan Tinggi : Universitas Trunojoyo Madura","title":"index"},{"location":"#assalamualaikum-","text":"","title":"Assalamualaikum^-^"},{"location":"#selamat-datang-di-halaman-tugas-penambangan-data","text":"Nama : Nur Khofifah Nim : 180411100139 Jurusan : Teknik Informatika Angkatan : 2018 Semester : 3 Mata Kuliah : Penambangan data-5D Perguruan Tinggi : Universitas Trunojoyo Madura","title":"Selamat Datang Di Halaman Tugas Penambangan Data"},{"location":"DECISION TREE/","text":"DECISION TREE \u00b6 decision tree merupakan metode klarifikasi yang sering digunakan atau metode paling polpuler ,keunggulannya adalah mudah di interprestasi oleh manusia .dicision tree merupakan suatu prediksi yang berupa pohon atau bisa disebut stuktur beriharki,konsep decision tree adalah mengubah data yang ada menjadi pohon keputusan dan aturan aturan keputusan. CARA MEMBUAT DECISION TREE \u00b6 \u200b Ada beberapa cara membuat decision tree disini saya akan membuat dengan cara mengurutkan poperty yang paling penting.sebulum itu kita harus tau rumus rumusnya berikut ini rumus dari entropy dan gain : $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ keterangan: S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S kemudian hitung nilai gain menggunakan rumus : $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ keterangan: S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S untuk mempermudah penghitungan saya menggunakan fungsi pembantu, seperti fungsi banyak_elemen untuk mengecek ada berapa elemen dalam sebuah kolom atau fiture/class. # menentukan value atau jenis pada atribut def banyak_elemen (kolom, data): kelas=[] for i in range (len(data)): if data.values.tolist()[i][kolom] not in kelas: kelas.append(data.values.tolist()[i][kolom]) return kelas kelas=banyak_elemen(df.shape[1]-1, df) outlook=banyak_elemen(df.shape[1]-5,df) temp=banyak_elemen(df.shape[1]-4,df) humidity=banyak_elemen(df.shape[1]-3,df) windy=banyak_elemen(df.shape[1]-2,df) print(kelas,outlook,temp,humidity,windy)` ['no', 'yes'] ['sunny', 'overcast', 'rainy'] ['hot', 'mild', 'cool'] ['high', 'normal'] [False, True] Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class. # menentukan count value pada Kelas def countvKelas(kelas,kolomKelas,data): hasil=[] for x in range(len(kelas)): hasil.append(0) for i in range (len(data)): for j in range (len(kelas)): if data.values.tolist()[i][kolomKelas] == kelas[j]: hasil[j]+=1 return hasil pKelas=countvKelas(kelas,df.shape[1]-1,df) pKelas [5, 9] Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture. # menentukan nilai entropy target def entropy(T): hasil=0 jumlah=0 for y in T: jumlah+=y for z in range (len(T)): if jumlah!=0: T[z]=T[z]/jumlah for i in T: if i != 0: hasil-=i*math.log(i,2) return hasil def e_list(atribut,n): temp=[] tx=t_list(atribut,n) for i in range (len(atribut)): ent=entropy(tx[i]) temp.append(ent) return temp tOutlook=t_list(outlook,5) tTemp=t_list(temp,4) tHum=t_list(humidity,3) tWin=t_list(windy,2) print(\"Sunny, Overcast, Rainy\",eOutlook) print(\"Hot, Mild, Cold\", eTemp) print(\"High, Normal\", eHum) print(\"False, True\", eWin) Sunny, Overcast, Rainy [0.9709505944546686, 0.0, 0.9709505944546686] Hot, Mild, Cold [1.0, 0.9182958340544896, 0.8112781244591328] High, Normal [0.9852281360342516, 0.5916727785823275] False, True [0.8112781244591328, 1.0] berikut contoh data yang akan di rubah menjadi decision tree \u200b 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari *entropy(s)* dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitu gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]}});","title":"DECISION TREE"},{"location":"DECISION TREE/#decision-tree","text":"decision tree merupakan metode klarifikasi yang sering digunakan atau metode paling polpuler ,keunggulannya adalah mudah di interprestasi oleh manusia .dicision tree merupakan suatu prediksi yang berupa pohon atau bisa disebut stuktur beriharki,konsep decision tree adalah mengubah data yang ada menjadi pohon keputusan dan aturan aturan keputusan.","title":"DECISION TREE"},{"location":"DECISION TREE/#cara-membuat-decision-tree","text":"\u200b Ada beberapa cara membuat decision tree disini saya akan membuat dengan cara mengurutkan poperty yang paling penting.sebulum itu kita harus tau rumus rumusnya berikut ini rumus dari entropy dan gain : $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ keterangan: S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S kemudian hitung nilai gain menggunakan rumus : $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ keterangan: S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S untuk mempermudah penghitungan saya menggunakan fungsi pembantu, seperti fungsi banyak_elemen untuk mengecek ada berapa elemen dalam sebuah kolom atau fiture/class. # menentukan value atau jenis pada atribut def banyak_elemen (kolom, data): kelas=[] for i in range (len(data)): if data.values.tolist()[i][kolom] not in kelas: kelas.append(data.values.tolist()[i][kolom]) return kelas kelas=banyak_elemen(df.shape[1]-1, df) outlook=banyak_elemen(df.shape[1]-5,df) temp=banyak_elemen(df.shape[1]-4,df) humidity=banyak_elemen(df.shape[1]-3,df) windy=banyak_elemen(df.shape[1]-2,df) print(kelas,outlook,temp,humidity,windy)` ['no', 'yes'] ['sunny', 'overcast', 'rainy'] ['hot', 'mild', 'cool'] ['high', 'normal'] [False, True] Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class. # menentukan count value pada Kelas def countvKelas(kelas,kolomKelas,data): hasil=[] for x in range(len(kelas)): hasil.append(0) for i in range (len(data)): for j in range (len(kelas)): if data.values.tolist()[i][kolomKelas] == kelas[j]: hasil[j]+=1 return hasil pKelas=countvKelas(kelas,df.shape[1]-1,df) pKelas [5, 9] Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture. # menentukan nilai entropy target def entropy(T): hasil=0 jumlah=0 for y in T: jumlah+=y for z in range (len(T)): if jumlah!=0: T[z]=T[z]/jumlah for i in T: if i != 0: hasil-=i*math.log(i,2) return hasil def e_list(atribut,n): temp=[] tx=t_list(atribut,n) for i in range (len(atribut)): ent=entropy(tx[i]) temp.append(ent) return temp tOutlook=t_list(outlook,5) tTemp=t_list(temp,4) tHum=t_list(humidity,3) tWin=t_list(windy,2) print(\"Sunny, Overcast, Rainy\",eOutlook) print(\"Hot, Mild, Cold\", eTemp) print(\"High, Normal\", eHum) print(\"False, True\", eWin) Sunny, Overcast, Rainy [0.9709505944546686, 0.0, 0.9709505944546686] Hot, Mild, Cold [1.0, 0.9182958340544896, 0.8112781244591328] High, Normal [0.9852281360342516, 0.5916727785823275] False, True [0.8112781244591328, 1.0] berikut contoh data yang akan di rubah menjadi decision tree \u200b 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari *entropy(s)* dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitu gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]}});","title":"CARA MEMBUAT DECISION TREE"},{"location":"MengukurJarak/","text":"Pengertian \u00b6 Disini kita akan belajar cara mengukur jarak data menggunakan beberapa cara atau metode Minkowski Distance \u00b6 Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Manhattan distance \u00b6 Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ implementasi \u00b6 silahkan implementasinya Disini disana lengkap dengan codingan dan outputannya MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Mengukur jarak"},{"location":"MengukurJarak/#pengertian","text":"Disini kita akan belajar cara mengukur jarak data menggunakan beberapa cara atau metode","title":"Pengertian"},{"location":"MengukurJarak/#minkowski-distance","text":"Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$","title":"Minkowski Distance"},{"location":"MengukurJarak/#manhattan-distance","text":"Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$","title":"Manhattan distance"},{"location":"MengukurJarak/#implementasi","text":"silahkan implementasinya Disini disana lengkap dengan codingan dan outputannya MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"implementasi"},{"location":"Missing Values/","text":"Missing Values using KNN \u00b6 KNN adalah algoritma yang berguna untuk mencocokkan suatu titik dengan tetangga terdekatnya dalam ruang multi-dimensi. Ini dapat digunakan untuk data yang kontinu, diskrit, ordinal, dan kategoris yang membuatnya sangat berguna untuk menangani semua jenis data yang hilang. Asumsi di balik menggunakan KNN untuk nilai yang hilang adalah bahwa nilai poin dapat didekati dengan nilai dari poin yang paling dekat dengannya, berdasarkan pada variabel lain. Mari kita simpan contoh sebelumnya dan tambahkan variabel lain, penghasilan orang tersebut. Sekarang kami memiliki tiga variabel, jenis kelamin, pendapatan dan tingkat depresi yang memiliki nilai yang hilang. Kami kemudian berasumsi bahwa orang-orang dengan pendapatan yang sama dan jenis kelamin yang sama cenderung memiliki tingkat depresi yang sama. Untuk nilai yang hilang, kita akan melihat jenis kelamin orang tersebut, pendapatannya, mencari k tetangga terdekatnya dan mendapatkan tingkat depresi mereka. Kita kemudian dapat memperkirakan tingkat depresi orang yang kita inginkan. Kalibrasi Parameter KNN \u00b6 Jumlah tetangga yang harus dicari \u00b6 Mengambil k rendah akan meningkatkan pengaruh kebisingan dan hasilnya akan kurang digeneralisasikan. Di sisi lain, mengambil k tinggi akan cenderung mengaburkan efek lokal yang persis apa yang kita cari. Juga disarankan untuk mengambil k yang aneh untuk kelas biner untuk menghindari ikatan. Metode agregasi untuk digunakan \u00b6 Di sini kita memungkinkan untuk mean aritmatika, median dan mode untuk variabel numerik dan mode untuk yang kategorikal Normalisasi data \u00b6 Ini adalah metode yang memungkinkan setiap atribut memberikan pengaruh yang sama dalam mengidentifikasi tetangga saat menghitung jenis jarak tertentu seperti yang Euclidean. Anda harus menormalkan data Anda ketika skala tidak memiliki arti dan / atau Anda memiliki skala tidak konsisten seperti sentimeter dan meter. Ini menyiratkan pengetahuan sebelumnya tentang data untuk mengetahui mana yang lebih penting. Algoritma secara otomatis menormalkan data ketika variabel numerik dan kategorikal disediakan. Atribut numerik jarak \u00b6 Di antara berbagai metrik jarak yang tersedia, kami akan fokus pada yang utama, Euclidean dan Manhattan. Euclidean adalah ukuran jarak yang baik untuk digunakan jika variabel input bertipe sama (mis. Semua lebar dan tinggi yang diukur). Jarak Manhattan adalah ukuran yang baik untuk digunakan jika variabel input tidak dalam jenis yang sama (seperti usia, tinggi, dll ...). Atribut kategorikal jarak \u00b6 tanpa transformasi sebelumnya, jarak yang berlaku terkait dengan frekuensi dan kesamaan. Atribut kategorikal hampir sama dengan nominal karena dengan tipe ini akan dinormalisasikan menjadi numerik atau angka untuk bisa dirukur jaraknya import pandas as pd import numpy as np dict = {'First Score':[100, 90, np.nan, 95], 'Second Score': [30, 45, 56, np.nan], 'Third Score':[np.nan, 40, 80, 98]} df = pd.DataFrame(dict) df.notnull() First Score Second Score Third Score 0 True True False 1 True True True 2 False True True 3 True False True","title":"Missing Values"},{"location":"Missing Values/#missing-values-using-knn","text":"KNN adalah algoritma yang berguna untuk mencocokkan suatu titik dengan tetangga terdekatnya dalam ruang multi-dimensi. Ini dapat digunakan untuk data yang kontinu, diskrit, ordinal, dan kategoris yang membuatnya sangat berguna untuk menangani semua jenis data yang hilang. Asumsi di balik menggunakan KNN untuk nilai yang hilang adalah bahwa nilai poin dapat didekati dengan nilai dari poin yang paling dekat dengannya, berdasarkan pada variabel lain. Mari kita simpan contoh sebelumnya dan tambahkan variabel lain, penghasilan orang tersebut. Sekarang kami memiliki tiga variabel, jenis kelamin, pendapatan dan tingkat depresi yang memiliki nilai yang hilang. Kami kemudian berasumsi bahwa orang-orang dengan pendapatan yang sama dan jenis kelamin yang sama cenderung memiliki tingkat depresi yang sama. Untuk nilai yang hilang, kita akan melihat jenis kelamin orang tersebut, pendapatannya, mencari k tetangga terdekatnya dan mendapatkan tingkat depresi mereka. Kita kemudian dapat memperkirakan tingkat depresi orang yang kita inginkan.","title":"Missing Values using KNN"},{"location":"Missing Values/#kalibrasi-parameter-knn","text":"","title":"Kalibrasi Parameter KNN"},{"location":"Missing Values/#jumlah-tetangga-yang-harus-dicari","text":"Mengambil k rendah akan meningkatkan pengaruh kebisingan dan hasilnya akan kurang digeneralisasikan. Di sisi lain, mengambil k tinggi akan cenderung mengaburkan efek lokal yang persis apa yang kita cari. Juga disarankan untuk mengambil k yang aneh untuk kelas biner untuk menghindari ikatan.","title":"Jumlah tetangga yang harus dicari"},{"location":"Missing Values/#metode-agregasi-untuk-digunakan","text":"Di sini kita memungkinkan untuk mean aritmatika, median dan mode untuk variabel numerik dan mode untuk yang kategorikal","title":"Metode agregasi untuk digunakan"},{"location":"Missing Values/#normalisasi-data","text":"Ini adalah metode yang memungkinkan setiap atribut memberikan pengaruh yang sama dalam mengidentifikasi tetangga saat menghitung jenis jarak tertentu seperti yang Euclidean. Anda harus menormalkan data Anda ketika skala tidak memiliki arti dan / atau Anda memiliki skala tidak konsisten seperti sentimeter dan meter. Ini menyiratkan pengetahuan sebelumnya tentang data untuk mengetahui mana yang lebih penting. Algoritma secara otomatis menormalkan data ketika variabel numerik dan kategorikal disediakan.","title":"Normalisasi data"},{"location":"Missing Values/#atribut-numerik-jarak","text":"Di antara berbagai metrik jarak yang tersedia, kami akan fokus pada yang utama, Euclidean dan Manhattan. Euclidean adalah ukuran jarak yang baik untuk digunakan jika variabel input bertipe sama (mis. Semua lebar dan tinggi yang diukur). Jarak Manhattan adalah ukuran yang baik untuk digunakan jika variabel input tidak dalam jenis yang sama (seperti usia, tinggi, dll ...).","title":"Atribut numerik jarak"},{"location":"Missing Values/#atribut-kategorikal-jarak","text":"tanpa transformasi sebelumnya, jarak yang berlaku terkait dengan frekuensi dan kesamaan. Atribut kategorikal hampir sama dengan nominal karena dengan tipe ini akan dinormalisasikan menjadi numerik atau angka untuk bisa dirukur jaraknya import pandas as pd import numpy as np dict = {'First Score':[100, 90, np.nan, 95], 'Second Score': [30, 45, 56, np.nan], 'Third Score':[np.nan, 40, 80, 98]} df = pd.DataFrame(dict) df.notnull() First Score Second Score Third Score 0 True True False 1 True True True 2 False True True 3 True False True","title":"Atribut kategorikal jarak"},{"location":"Tugas 5 - Clustering/","text":"CLUSTERING \u00b6 Clustering adalah metode penganalisaan data yang sering dimasukkan sebagai salah satu metode Data Mining yang tujuannya adalah untuk mengelompokkan data dengan karakteristik yang sama ke suatu wilayah yang sama dan data dengan karakteristik yang berbeda ke wilayah yang lain. \u200b Ada beberapa pendekatan yang digunakan dalam mengembangkan metode clustering, dua pendekatan utama adalah clustering dengan pendekatan partisi dan clustering dengan pendekatan hirarki. Clustering dengan pendekatan partisi atau sering disebut dengan partition-based clustering mengelompokkan data dengan memilah-milah data yang dianalisa ke dalam cluster-cluster yang ada. Clustering dengan pendekatan hirarki atau sering disebut dengan hierarchical clustering mengelompokkan data dengan membuat suatu hirarki berupa dendogram dimana data yang mirip akan ditempatkan pada hirarki yang berdekatan dan yang tidak pada hirarki yang berjauhan. Di samping kedua pendekatan tersebut, ada juga clustering dengan pendekatan automatic mapping (Self-Organising Map/SOM). Clustering dengan pendekatan partisi \u00b6 1. K-Means \u200b Salah satu metode yang banyak digunakan dalam melakukan clustering dengan partisi ini adalah metode k-means. Secara umum metode k-means ini melakukan proses pengelompokan dengan prosedur sebagai berikut: \u00b7 Tentukan jumlah cluster \u00b7 Alokasikan data secara random ke cluster yang ada \u00b7 Hitung rata-rata setiap cluster dari data yang tergabung di dalamnya \u00b7 Alokasikan kembali semua data ke cluster terdekat \u00b7 Ulang proses nomor 3, sampai tidak ada perubahan atau perubahan yang terjadi masih sudah di bawah treshold \u200b Prosedur dasar ini bisa berubah mengikuti pendekatan pengalokasian data yang diterapkan, apakah crisp atau fuzzy . Setelah meneliti clustering dari sudut yang lain, saya menemukan bahwa k-means clustering mempunyai beberapa kelemahan. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. karakteristik dari algoritma ini adalah : . Memiliki n buah data. . Input berupa jumlah data dan jumlah cluster (kelompok). . Pada setiap cluster/kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut. Algoritma K-Means \u00b6 \u200b Secara sederhana algoritma K-Means dimulai dari tahap berikut : . Pilih K buah titik centroid. . Menghitung jarak data dengan centroid. . Update nilai titik centroid. . Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah. Rumus K-Means \u00b6 Metode K-Modes \u00b6 \u200b K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster. Metode K-Prototype \u00b6 \u200b Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu. Algoritma K-Prototype \u00b6 \u200b Sebelum masuk proses algoritma K-Prototypes tentukan jumlah k yang akan dibentuk batasannya minimal 2 dan maksimal \u221an atau n/2 dimana n adalah jumlah data point atau obyek . Tahap 1 : Tentukan K dengan inisial kluster z1, z2, ..., zk secara acak dari n buah titik {x1, x2, ..., xn} . Tahap 2 : Hitung jarak seluruh data point pada data set terhadap inisial kluster awal, alokasikan data point ke dalam cluster yang memiliki jarak prototype terdekat dengan object yang diukur. . Tahap 3 : Hitung titik pusat cluster yang baru setelah semua objek dialokasikan. Lalu realokasikan semua datapoint pada dataset terhadap prototype yang baru. . Tahap 4 : jika titik pusat cluster tidak berubah atau sudah konvergen maka proses algoritma berhenti tetapi jika titik pusat masih berubah-ubah secara signifikan maka proses kembali ke tahap 2 dan 3 hingga iterasi maksimum tercapai atau sudah tidak ada perpindahan objek. Rumus K-Prototype \u00b6 2. Mixture Modelling (Mixture Modeling) \u200b Mixture modelling merupakan metode pengelompokan data yang mirip dengan k-means dengan kelebihan penggunaan distribusi statistik dalam mendefinisikan setiap cluster yang ditemukan. Dibandingkan dengan k-means yang hanya menggunakan cluster center, penggunaan distribusi statistik ini mengijinkan kita untuk: \u00b7 Memodel data yang kita miliki dengan setting karakteristik yang berbeda-beda \u00b7 Jumlah cluster yang sesuai dengan keadaan data bisa ditemukan seiring dengan proses pemodelan karakteristik dari masing-masing cluster \u00b7 Hasil pemodelan clustering yang dilaksanakan bisa diuji tingkat keakuratannya \u200b Distribusi statistik yang digunakan bisa bermacam-macam mulai dari yang digunakan untuk data categorical sampai yang continuous, termasuk di antaranya distribusi binomial, multinomial, normal dan lain-lain. Beberapa distribusi yang bersifat tidak normal seperti distribusi Poisson, von-Mises, Gamma dan Student t, juga diterapkan untuk bisa mengakomodasi berbagai keadaan data yang ada di lapangan. Beberapa pendekatan multivariate juga banyak diterapkan untuk memperhitungkan tingkat keterkaitan antara variabel data yang satu dengan yang lainnya. Clustering dengan Pendekatan Hirarki \u00b6 \u200b Clustering dengan pendekatan hirarki mengelompokkan data yang mirip dalam hirarki yang sama dan yang tidak mirip di hirarki yang agak jauh. Ada dua metode yang sering diterapkan yaitu agglomerative hieararchical clustering dan divisive hierarchical clustering . Agglomerative melakukan proses clustering dari N cluster menjadi satu kesatuan cluster, dimana N adalah jumlah data, sedangkan divisive melakukan proses clustering yang sebaliknya yaitu dari satu cluster menjadi N cluster. \u200b Beberapa metode hierarchical clustering yang sering digunakan dibedakan menurut cara mereka untuk menghitung tingkat kemiripan. Ada yang menggunakan Single Linkage , Complete Linkage , Average Linkage , Average Group Linkage dan lain-lainnya. Seperti juga halnya dengan partition-based clustering , kita juga bisa memilih jenis jarak yang digunakan untuk menghitung tingkat kemiripan antar data. \u200b Salah satu cara untuk mempermudah pengembangan dendogram untuk hierarchical clustering ini adalah dengan membuat similarity matrix yang memuat tingkat kemiripan antar data yang dikelompokkan. Tingkat kemiripan bisa dihitung dengan berbagai macam cara seperti dengan Euclidean Distance Space. Berangkat dari similarity matrix ini, kita bisa memilih lingkage jenis mana yang akan digunakan untuk mengelompokkan data yang dianalisa. Clustering Dengan Pendekatan Automatic Mapping (Self-Organising Map/SOM) \u00b6 \u200b Self-Organising Map merupakan suatu tipe Artificial Neural Networks yang di-training secara unsupervised. SOM menghasilkan map yang terdiri dari output dalam dimensi yang rendah (2 atau 3 dimensi). Map ini berusaha mencari property dari input data. Komposisi input dan output dalam SOM mirip dengan komposisi dari proses feature scaling (multidimensional scaling). \u200b Walaupun proses learning yang dilakukan mirip dengan Artificial Neural Networks, tetapi proses untuk meng-assign input data ke map, lebih mirip dengan K-Means dan kNN Algorithm. Adapun prosedur yang ditempuh dalam melakukan clustering dengan SOM adalah sebagai berikut: \u00b7 Tentukan weight dari input data secara random \u00b7 Pilih salah satu input data \u00b7 Hitung tingkat kesamaan (dengan Eucledian) antara input data dan weight dari input data tersebut dan pilih input data yang memiliki kesamaan dengan weight yang ada (data ini disebut dengan Best Matching Unit (BMU)) \u00b7 Perbaharui weight dari input data dengan mendekatkan weight tersebut ke BMU dengan rumus: Wv(t+1) = Wv(t) + Theta(v, t) x Alpha(t) x (D(t) \u2013 Wv(t)) Dimana: o Wv(t) : Weight pada saat ke-t o Theta (v, t) : Fungsi neighbourhood yang tergantung pada Lattice distance antara BMU dengan neuron v. Umumnya bernilai 1 untuk neuron yang cukup dekat dengan BMU, dan 0 untuk yang sebaliknya. Penggunaan fungsi Gaussian juga memungkinkan. o Alpha (t) : Learning Coefficient yang berkurang secara monotonic o D(t) : Input data \u00b7 Tambah nilai t, sampai t < Lambda , dimana Lambda adalah jumlah iterasi MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Clustering"},{"location":"Tugas 5 - Clustering/#clustering","text":"Clustering adalah metode penganalisaan data yang sering dimasukkan sebagai salah satu metode Data Mining yang tujuannya adalah untuk mengelompokkan data dengan karakteristik yang sama ke suatu wilayah yang sama dan data dengan karakteristik yang berbeda ke wilayah yang lain. \u200b Ada beberapa pendekatan yang digunakan dalam mengembangkan metode clustering, dua pendekatan utama adalah clustering dengan pendekatan partisi dan clustering dengan pendekatan hirarki. Clustering dengan pendekatan partisi atau sering disebut dengan partition-based clustering mengelompokkan data dengan memilah-milah data yang dianalisa ke dalam cluster-cluster yang ada. Clustering dengan pendekatan hirarki atau sering disebut dengan hierarchical clustering mengelompokkan data dengan membuat suatu hirarki berupa dendogram dimana data yang mirip akan ditempatkan pada hirarki yang berdekatan dan yang tidak pada hirarki yang berjauhan. Di samping kedua pendekatan tersebut, ada juga clustering dengan pendekatan automatic mapping (Self-Organising Map/SOM).","title":"CLUSTERING"},{"location":"Tugas 5 - Clustering/#clustering-dengan-pendekatan-partisi","text":"1. K-Means \u200b Salah satu metode yang banyak digunakan dalam melakukan clustering dengan partisi ini adalah metode k-means. Secara umum metode k-means ini melakukan proses pengelompokan dengan prosedur sebagai berikut: \u00b7 Tentukan jumlah cluster \u00b7 Alokasikan data secara random ke cluster yang ada \u00b7 Hitung rata-rata setiap cluster dari data yang tergabung di dalamnya \u00b7 Alokasikan kembali semua data ke cluster terdekat \u00b7 Ulang proses nomor 3, sampai tidak ada perubahan atau perubahan yang terjadi masih sudah di bawah treshold \u200b Prosedur dasar ini bisa berubah mengikuti pendekatan pengalokasian data yang diterapkan, apakah crisp atau fuzzy . Setelah meneliti clustering dari sudut yang lain, saya menemukan bahwa k-means clustering mempunyai beberapa kelemahan. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. karakteristik dari algoritma ini adalah : . Memiliki n buah data. . Input berupa jumlah data dan jumlah cluster (kelompok). . Pada setiap cluster/kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut.","title":"Clustering dengan pendekatan partisi"},{"location":"Tugas 5 - Clustering/#algoritma-k-means","text":"\u200b Secara sederhana algoritma K-Means dimulai dari tahap berikut : . Pilih K buah titik centroid. . Menghitung jarak data dengan centroid. . Update nilai titik centroid. . Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah.","title":"Algoritma K-Means"},{"location":"Tugas 5 - Clustering/#rumus-k-means","text":"","title":"Rumus K-Means"},{"location":"Tugas 5 - Clustering/#metode-k-modes","text":"\u200b K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster.","title":"Metode K-Modes"},{"location":"Tugas 5 - Clustering/#metode-k-prototype","text":"\u200b Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu.","title":"Metode K-Prototype"},{"location":"Tugas 5 - Clustering/#algoritma-k-prototype","text":"\u200b Sebelum masuk proses algoritma K-Prototypes tentukan jumlah k yang akan dibentuk batasannya minimal 2 dan maksimal \u221an atau n/2 dimana n adalah jumlah data point atau obyek . Tahap 1 : Tentukan K dengan inisial kluster z1, z2, ..., zk secara acak dari n buah titik {x1, x2, ..., xn} . Tahap 2 : Hitung jarak seluruh data point pada data set terhadap inisial kluster awal, alokasikan data point ke dalam cluster yang memiliki jarak prototype terdekat dengan object yang diukur. . Tahap 3 : Hitung titik pusat cluster yang baru setelah semua objek dialokasikan. Lalu realokasikan semua datapoint pada dataset terhadap prototype yang baru. . Tahap 4 : jika titik pusat cluster tidak berubah atau sudah konvergen maka proses algoritma berhenti tetapi jika titik pusat masih berubah-ubah secara signifikan maka proses kembali ke tahap 2 dan 3 hingga iterasi maksimum tercapai atau sudah tidak ada perpindahan objek.","title":"Algoritma K-Prototype"},{"location":"Tugas 5 - Clustering/#rumus-k-prototype","text":"2. Mixture Modelling (Mixture Modeling) \u200b Mixture modelling merupakan metode pengelompokan data yang mirip dengan k-means dengan kelebihan penggunaan distribusi statistik dalam mendefinisikan setiap cluster yang ditemukan. Dibandingkan dengan k-means yang hanya menggunakan cluster center, penggunaan distribusi statistik ini mengijinkan kita untuk: \u00b7 Memodel data yang kita miliki dengan setting karakteristik yang berbeda-beda \u00b7 Jumlah cluster yang sesuai dengan keadaan data bisa ditemukan seiring dengan proses pemodelan karakteristik dari masing-masing cluster \u00b7 Hasil pemodelan clustering yang dilaksanakan bisa diuji tingkat keakuratannya \u200b Distribusi statistik yang digunakan bisa bermacam-macam mulai dari yang digunakan untuk data categorical sampai yang continuous, termasuk di antaranya distribusi binomial, multinomial, normal dan lain-lain. Beberapa distribusi yang bersifat tidak normal seperti distribusi Poisson, von-Mises, Gamma dan Student t, juga diterapkan untuk bisa mengakomodasi berbagai keadaan data yang ada di lapangan. Beberapa pendekatan multivariate juga banyak diterapkan untuk memperhitungkan tingkat keterkaitan antara variabel data yang satu dengan yang lainnya.","title":"Rumus K-Prototype"},{"location":"Tugas 5 - Clustering/#clustering-dengan-pendekatan-hirarki","text":"\u200b Clustering dengan pendekatan hirarki mengelompokkan data yang mirip dalam hirarki yang sama dan yang tidak mirip di hirarki yang agak jauh. Ada dua metode yang sering diterapkan yaitu agglomerative hieararchical clustering dan divisive hierarchical clustering . Agglomerative melakukan proses clustering dari N cluster menjadi satu kesatuan cluster, dimana N adalah jumlah data, sedangkan divisive melakukan proses clustering yang sebaliknya yaitu dari satu cluster menjadi N cluster. \u200b Beberapa metode hierarchical clustering yang sering digunakan dibedakan menurut cara mereka untuk menghitung tingkat kemiripan. Ada yang menggunakan Single Linkage , Complete Linkage , Average Linkage , Average Group Linkage dan lain-lainnya. Seperti juga halnya dengan partition-based clustering , kita juga bisa memilih jenis jarak yang digunakan untuk menghitung tingkat kemiripan antar data. \u200b Salah satu cara untuk mempermudah pengembangan dendogram untuk hierarchical clustering ini adalah dengan membuat similarity matrix yang memuat tingkat kemiripan antar data yang dikelompokkan. Tingkat kemiripan bisa dihitung dengan berbagai macam cara seperti dengan Euclidean Distance Space. Berangkat dari similarity matrix ini, kita bisa memilih lingkage jenis mana yang akan digunakan untuk mengelompokkan data yang dianalisa.","title":"Clustering dengan Pendekatan Hirarki"},{"location":"Tugas 5 - Clustering/#clustering-dengan-pendekatan-automatic-mapping-self-organising-mapsom","text":"\u200b Self-Organising Map merupakan suatu tipe Artificial Neural Networks yang di-training secara unsupervised. SOM menghasilkan map yang terdiri dari output dalam dimensi yang rendah (2 atau 3 dimensi). Map ini berusaha mencari property dari input data. Komposisi input dan output dalam SOM mirip dengan komposisi dari proses feature scaling (multidimensional scaling). \u200b Walaupun proses learning yang dilakukan mirip dengan Artificial Neural Networks, tetapi proses untuk meng-assign input data ke map, lebih mirip dengan K-Means dan kNN Algorithm. Adapun prosedur yang ditempuh dalam melakukan clustering dengan SOM adalah sebagai berikut: \u00b7 Tentukan weight dari input data secara random \u00b7 Pilih salah satu input data \u00b7 Hitung tingkat kesamaan (dengan Eucledian) antara input data dan weight dari input data tersebut dan pilih input data yang memiliki kesamaan dengan weight yang ada (data ini disebut dengan Best Matching Unit (BMU)) \u00b7 Perbaharui weight dari input data dengan mendekatkan weight tersebut ke BMU dengan rumus: Wv(t+1) = Wv(t) + Theta(v, t) x Alpha(t) x (D(t) \u2013 Wv(t)) Dimana: o Wv(t) : Weight pada saat ke-t o Theta (v, t) : Fungsi neighbourhood yang tergantung pada Lattice distance antara BMU dengan neuron v. Umumnya bernilai 1 untuk neuron yang cukup dekat dengan BMU, dan 0 untuk yang sebaliknya. Penggunaan fungsi Gaussian juga memungkinkan. o Alpha (t) : Learning Coefficient yang berkurang secara monotonic o D(t) : Input data \u00b7 Tambah nilai t, sampai t < Lambda , dimana Lambda adalah jumlah iterasi MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Clustering Dengan Pendekatan Automatic Mapping (Self-Organising Map/SOM)"},{"location":"statistik/","text":"Pengertian Statistik \u00b6 /Statistik yaitu merupakan suatu ilmu yang mempelajari tentang cara \u2013 cara pengumpulan data, penyajian data, dan juga analisis dan interpretasi tentang data tersebut. Pengertian Statistik Deskriptif \u00b6 Statistik deskriptif yaitu merupakan metode \u2013 metode yang juga berkaitan dengan pengumpulan dan Penyajian suatu gugus data sehingga dapat memberikan informasi yang berguna. Statistika deskriptif memberikan informasi hanya mengenai data yang dipunyai dan tidak sama sekali untuk menarik iferensia atau kesimpulan apapun tentang data \u2013 data tersebut. Tipe Statistik Deskriptif \u00b6 Mean (rata-rata) \u00b6 Mean adalah nilai rata-rata dari beberapa buah data. Nilai mean dapat ditentukan dengan membagi jumlah data dengan banyaknya data. Mean (rata-rata) merupakan suatu ukuran pemusatan data. Mean suatu data juga merupakan statistik karena mampu menggambarkan bahwa data tersebut berada pada kisaran mean data tersebut. Mean tidak dapat digunakan sebagai ukuran pemusatan untuk jenis data nominal dan ordinal. Berdasarkan definisi dari mean adalah jumlah seluruh data dibagi dengan banyaknya data. Dengan kata lain jika kita memiliki N data sebagai berikut maka mean data tersebut dapat kita tuliskan sebagai berikut : $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Dimana: x = data ke n x bar = x rata-rata = nilai rata-rata sampel n = banyaknya data Median \u00b6 Median menentukan letak tengah data setelah data disusun menurut urutan nilainya. Bisa juga *nilai tengah dari data-data yang terurut. Simbol untuk median adalah Me. Dengan median Me, maka 50% dari banyak data nilainya paling tinggi sama dengan Me, dan 50% dari banyak data nilainya paling rendah sama dengan Me. Dalam mencari median, dibedakan untuk banyak data ganjil dan banyak data genap. Untuk banyak data ganjil, setelah data disusun menurut nilainya, maka median Me adalah data yang terletak tepat di tengah. Median bisa dihitung menggunakan rumus sebagai berikut: $$ Me=Q_2 =\\left( \\begin{matrix} ^xn+1 \\over 2 \\end{matrix} \\right), jika n ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {^xn \\over 2 } {^xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika n genap $$ Dimana: Mo = Modus L = Tepi bawah kelas yang memiliki frekuensi tertinggi (kelas modus) i = Interval kelas b1 = Frekuensi kelas modus dikurangi frekuensi kelas interval terdekat sebelumnya b2 = frekuensi kelas modus dikurangi frekuensi kelas interval terdekat sesudahnya Standar Deviasi \u00b6 Standar Deviasi dan Varians Salah satu teknik statistik yg digunakan untuk menjelaskan homogenitas kelompok. Varians merupakan jumlah kuadrat semua deviasi nilai-nilai individual terhadap rata-rata kelompok. Sedangkan akar dari varians disebut dengan standar deviasi atau simpangan baku. Standar Deviasi dan Varians Simpangan baku merupakan variasi sebaran data. Semakin kecil nilai sebarannya berarti variasi nilai data makin sama Jika sebarannya bernilai 0, maka nilai semua datanya adalah sama. Semakin besar nilai sebarannya berarti data semakin bervariasi. Standar Deviasi bisa didapat menggunakan rumus sebagai berikut: $$ \\sigma = {\\sqrt{ \\sum \\limits_{i=1}^{n} {(x_1-\\bar x)^2 } \\over n }} $$ Dimana : x = data ke n x bar = x rata-rata = nilai rata-rata sampel n = banyaknya data Varians \u00b6 Varians merupakan rata-rata dari selisih kuadrat tersebut merupakan suatu ukuran penyimpangan dari observasi. Simbol varians pada ukuran populasi sigma kuarat dan pada ukuran sample S2. Akar dari varians dinamakan standar deviasi atau simpangan baku. Varians bisa didapat menggunakan rumus sebagai berikut: $$ S^2 = {\\sqrt{ \\sum \\limits_{i=1}^{n} {(x_1-\\bar x)^2 } \\over n-1 }} $$ Skewness \u00b6 Skewness ( kemencengan ) adalah derajat ketidaksimetrisan suatu distribusi. Jika kurva frekuensi suatu distribusi memiliki ekor yang lebih memanjang ke kanan (dilihat dari meannya) maka dikatakan menceng kanan (positif) dan jika sebaliknya maka menceng kiri (negatif). Secara perhitungan, skewness adalah momen ketiga terhadap mean. Distribusi normal (dan distribusi simetris lainnya, misalnya distribusi t atau Cauchy) memiliki skewness 0 (nol). Skewness bisa dihitung menggunakan rumus sebagai berikut: $$ Skewness (S) = {{1 \\over T\\sigma^3} \\sum \\limits_{i=1}^{n}(r_2 - \\mu)^3} $$ Quartile Quartile adalah nilai-nilai yang membagi segugus pengamatan menjadi empat bagian sama besar. Nilai-nilai itu, yang dilambangkan dengan Q1, Q2, dan Q3, mempunyai sifat bahwa 25% data jatuh dibawah Q1, 50% data jatuh dibawah Q2, dan 75% data jatuh dibawah Q3. Quartile bisa dihitung menggunakan rumus sebagai berikut: $$ Q_1 = {x_{{1\\over4}(n+1)}} $$ $$ Q_2 = {x_{{1\\over2}(n+1)}} $$ $$ Q_3 = {x_{{3\\over4}(n+1)}} $$ Penerapan statistik deskriptif menggunakan python \u00b6 Alat dan Bahan \u00b6 Pada penerapan ini saya menggunakan 500 data random yang disimpan dalam bentuk .csv dan untuk mempermudah dalam penerapan tersebut, perlu disiapkan library python yang dapat didownload secara gratis. dalam kasus ini library python yang digunakan adalah sebagai berikut: pandas, digunakan untuk data manajemen dan data analysis. scipy, berisi kumpulan algoritme dan fungsi matematika. Pertama \u00b6 pada langkah ini kita memasukkan library yang telah disiapkan sebelumya import pandas as pd from scipy import stats Kedua \u00b6 dan selanjutnya memuat data csv yang telah disiapkan df = pd.read_csv('Data.csv',sep=';') Ketiga \u00b6 kemudian membuat data penyimpanan ( dictionary ) yang menampung nilai yang akan ditampilkan. selanjutnya mengambil data dari beberapa kolom pada csv dengan cara diiterasi serta menghitungnya dengan berbagai metode yang telah disiapkan oleh pandas itu sendiri. kemudian hasil tersebut di disimpan pada penyimpanan tadi data = {\"Stats\" : ['Min','Max','Mean','Standard Deviasi','Variasi','Skewnes', 'Quartile 1','Quartile 2', 'Quartile 3', 'Median','Modus']} for i in df.columns: data[i] = [df[i].min(), df[i].max(), df[i].mean(), round(df[i].std(), 2),round(df[i].var(), 2), round(df[i].skew(), 2), df[i].quantile(0.25), df[i].quantile(0.5), df[i].quantile(0.75), df[i].median(), stats.mode(df[i]).mode[0]] Keempat \u00b6 terakhir adalah menvisualisasikan hasil tersebut dalam bentuk dataframe tes = pd.DataFrame(data) tes.style.hide_index() stats data 1 data 2 data 3 data 4 min 40 153 7 55 max 80 178 56 100 mean 62.03 165.41 28.87 75.39 Standart deviasi 11.74 7.69 13.61 12.54 variasi 137.83 59.11 185.31 157.37 skewnes -0.15 0.1 0.19 0.09 quantile 1 52 159 17 64 quantile 2 61 165.5 28 74.5 quantile 3 73 172.25 41 85.25 median 62.03 165.41 28.61 75.39 modus 56 161 18 59 Source \u00b6 Seluruh file percobaan ada pada link berikut : disini Referensi http://blog.ub.ac.id/adiarsa/2012/03/14/mean-median-modus-dan-standar-deviasi/ http://statutorial.blogspot.com/2008/01/skewness-dan-kurtosis.html https://www.rumusstatistik.com/2013/07/varian-dan-standar-deviasi-simpangan.html https://www.rumusstatistik.com/2016/12/membuat-rumus-matematika-dengan-latex.html https://englishccit.wordpress.com/2012/03/27/pengertian-statistik-deskriptif/#more-1194 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"statistik deskriptif"},{"location":"statistik/#pengertian-statistik","text":"/Statistik yaitu merupakan suatu ilmu yang mempelajari tentang cara \u2013 cara pengumpulan data, penyajian data, dan juga analisis dan interpretasi tentang data tersebut.","title":"Pengertian Statistik"},{"location":"statistik/#pengertian-statistik-deskriptif","text":"Statistik deskriptif yaitu merupakan metode \u2013 metode yang juga berkaitan dengan pengumpulan dan Penyajian suatu gugus data sehingga dapat memberikan informasi yang berguna. Statistika deskriptif memberikan informasi hanya mengenai data yang dipunyai dan tidak sama sekali untuk menarik iferensia atau kesimpulan apapun tentang data \u2013 data tersebut.","title":"Pengertian Statistik Deskriptif"},{"location":"statistik/#tipe-statistik-deskriptif","text":"","title":"Tipe Statistik Deskriptif"},{"location":"statistik/#mean-rata-rata","text":"Mean adalah nilai rata-rata dari beberapa buah data. Nilai mean dapat ditentukan dengan membagi jumlah data dengan banyaknya data. Mean (rata-rata) merupakan suatu ukuran pemusatan data. Mean suatu data juga merupakan statistik karena mampu menggambarkan bahwa data tersebut berada pada kisaran mean data tersebut. Mean tidak dapat digunakan sebagai ukuran pemusatan untuk jenis data nominal dan ordinal. Berdasarkan definisi dari mean adalah jumlah seluruh data dibagi dengan banyaknya data. Dengan kata lain jika kita memiliki N data sebagai berikut maka mean data tersebut dapat kita tuliskan sebagai berikut : $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Dimana: x = data ke n x bar = x rata-rata = nilai rata-rata sampel n = banyaknya data","title":"Mean (rata-rata)"},{"location":"statistik/#median","text":"Median menentukan letak tengah data setelah data disusun menurut urutan nilainya. Bisa juga *nilai tengah dari data-data yang terurut. Simbol untuk median adalah Me. Dengan median Me, maka 50% dari banyak data nilainya paling tinggi sama dengan Me, dan 50% dari banyak data nilainya paling rendah sama dengan Me. Dalam mencari median, dibedakan untuk banyak data ganjil dan banyak data genap. Untuk banyak data ganjil, setelah data disusun menurut nilainya, maka median Me adalah data yang terletak tepat di tengah. Median bisa dihitung menggunakan rumus sebagai berikut: $$ Me=Q_2 =\\left( \\begin{matrix} ^xn+1 \\over 2 \\end{matrix} \\right), jika n ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {^xn \\over 2 } {^xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika n genap $$ Dimana: Mo = Modus L = Tepi bawah kelas yang memiliki frekuensi tertinggi (kelas modus) i = Interval kelas b1 = Frekuensi kelas modus dikurangi frekuensi kelas interval terdekat sebelumnya b2 = frekuensi kelas modus dikurangi frekuensi kelas interval terdekat sesudahnya","title":"Median"},{"location":"statistik/#standar-deviasi","text":"Standar Deviasi dan Varians Salah satu teknik statistik yg digunakan untuk menjelaskan homogenitas kelompok. Varians merupakan jumlah kuadrat semua deviasi nilai-nilai individual terhadap rata-rata kelompok. Sedangkan akar dari varians disebut dengan standar deviasi atau simpangan baku. Standar Deviasi dan Varians Simpangan baku merupakan variasi sebaran data. Semakin kecil nilai sebarannya berarti variasi nilai data makin sama Jika sebarannya bernilai 0, maka nilai semua datanya adalah sama. Semakin besar nilai sebarannya berarti data semakin bervariasi. Standar Deviasi bisa didapat menggunakan rumus sebagai berikut: $$ \\sigma = {\\sqrt{ \\sum \\limits_{i=1}^{n} {(x_1-\\bar x)^2 } \\over n }} $$ Dimana : x = data ke n x bar = x rata-rata = nilai rata-rata sampel n = banyaknya data","title":"Standar Deviasi"},{"location":"statistik/#varians","text":"Varians merupakan rata-rata dari selisih kuadrat tersebut merupakan suatu ukuran penyimpangan dari observasi. Simbol varians pada ukuran populasi sigma kuarat dan pada ukuran sample S2. Akar dari varians dinamakan standar deviasi atau simpangan baku. Varians bisa didapat menggunakan rumus sebagai berikut: $$ S^2 = {\\sqrt{ \\sum \\limits_{i=1}^{n} {(x_1-\\bar x)^2 } \\over n-1 }} $$","title":"Varians"},{"location":"statistik/#skewness","text":"Skewness ( kemencengan ) adalah derajat ketidaksimetrisan suatu distribusi. Jika kurva frekuensi suatu distribusi memiliki ekor yang lebih memanjang ke kanan (dilihat dari meannya) maka dikatakan menceng kanan (positif) dan jika sebaliknya maka menceng kiri (negatif). Secara perhitungan, skewness adalah momen ketiga terhadap mean. Distribusi normal (dan distribusi simetris lainnya, misalnya distribusi t atau Cauchy) memiliki skewness 0 (nol). Skewness bisa dihitung menggunakan rumus sebagai berikut: $$ Skewness (S) = {{1 \\over T\\sigma^3} \\sum \\limits_{i=1}^{n}(r_2 - \\mu)^3} $$ Quartile Quartile adalah nilai-nilai yang membagi segugus pengamatan menjadi empat bagian sama besar. Nilai-nilai itu, yang dilambangkan dengan Q1, Q2, dan Q3, mempunyai sifat bahwa 25% data jatuh dibawah Q1, 50% data jatuh dibawah Q2, dan 75% data jatuh dibawah Q3. Quartile bisa dihitung menggunakan rumus sebagai berikut: $$ Q_1 = {x_{{1\\over4}(n+1)}} $$ $$ Q_2 = {x_{{1\\over2}(n+1)}} $$ $$ Q_3 = {x_{{3\\over4}(n+1)}} $$","title":"Skewness"},{"location":"statistik/#penerapan-statistik-deskriptif-menggunakan-python","text":"","title":"Penerapan statistik deskriptif menggunakan python"},{"location":"statistik/#alat-dan-bahan","text":"Pada penerapan ini saya menggunakan 500 data random yang disimpan dalam bentuk .csv dan untuk mempermudah dalam penerapan tersebut, perlu disiapkan library python yang dapat didownload secara gratis. dalam kasus ini library python yang digunakan adalah sebagai berikut: pandas, digunakan untuk data manajemen dan data analysis. scipy, berisi kumpulan algoritme dan fungsi matematika.","title":"Alat dan Bahan"},{"location":"statistik/#pertama","text":"pada langkah ini kita memasukkan library yang telah disiapkan sebelumya import pandas as pd from scipy import stats","title":"Pertama"},{"location":"statistik/#kedua","text":"dan selanjutnya memuat data csv yang telah disiapkan df = pd.read_csv('Data.csv',sep=';')","title":"Kedua"},{"location":"statistik/#ketiga","text":"kemudian membuat data penyimpanan ( dictionary ) yang menampung nilai yang akan ditampilkan. selanjutnya mengambil data dari beberapa kolom pada csv dengan cara diiterasi serta menghitungnya dengan berbagai metode yang telah disiapkan oleh pandas itu sendiri. kemudian hasil tersebut di disimpan pada penyimpanan tadi data = {\"Stats\" : ['Min','Max','Mean','Standard Deviasi','Variasi','Skewnes', 'Quartile 1','Quartile 2', 'Quartile 3', 'Median','Modus']} for i in df.columns: data[i] = [df[i].min(), df[i].max(), df[i].mean(), round(df[i].std(), 2),round(df[i].var(), 2), round(df[i].skew(), 2), df[i].quantile(0.25), df[i].quantile(0.5), df[i].quantile(0.75), df[i].median(), stats.mode(df[i]).mode[0]]","title":"Ketiga"},{"location":"statistik/#keempat","text":"terakhir adalah menvisualisasikan hasil tersebut dalam bentuk dataframe tes = pd.DataFrame(data) tes.style.hide_index() stats data 1 data 2 data 3 data 4 min 40 153 7 55 max 80 178 56 100 mean 62.03 165.41 28.87 75.39 Standart deviasi 11.74 7.69 13.61 12.54 variasi 137.83 59.11 185.31 157.37 skewnes -0.15 0.1 0.19 0.09 quantile 1 52 159 17 64 quantile 2 61 165.5 28 74.5 quantile 3 73 172.25 41 85.25 median 62.03 165.41 28.61 75.39 modus 56 161 18 59","title":"Keempat"},{"location":"statistik/#source","text":"Seluruh file percobaan ada pada link berikut : disini Referensi http://blog.ub.ac.id/adiarsa/2012/03/14/mean-median-modus-dan-standar-deviasi/ http://statutorial.blogspot.com/2008/01/skewness-dan-kurtosis.html https://www.rumusstatistik.com/2013/07/varian-dan-standar-deviasi-simpangan.html https://www.rumusstatistik.com/2016/12/membuat-rumus-matematika-dengan-latex.html https://englishccit.wordpress.com/2012/03/27/pengertian-statistik-deskriptif/#more-1194 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Source"}]}